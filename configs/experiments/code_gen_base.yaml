# file_path: mlx_rl_trainer/configs/experiments/code_gen_base.yaml
# revision_no = 002
# goals_of_writing_code_block: Define a Pydantic-validated configuration for a code generation RL training task, adding num_rollout_samples.
# type_of_code_response: change existing
# Production-ready configuration for a code generation task using GRPO.
# This file is validated against the pydantic schemas in src/mlx_rl_trainer/core/config.py.

trainer:
  algorithm: "grpo"
  output_dir: "./outputs/code_gen_run_001"
  num_training_steps: 1000
  learning_rate: 2.0e-6
  ppo_batch_size: 2       # Number of unique prompts per micro-batch
  num_rollout_samples: 2  # Number of responses to generate per prompt
  grad_accum_steps: 4
  save_every: 250
  eval_every: 100
  grpo_beta: 0.05
  seed: 42

model:
  model_path: "./models/mock_model"
  ref_model_path: "./models/mock_model"
  use_lora: false
  lora_rank: 16

data:
  train_path: "./data/dummy_train.jsonl"
  val_path: "./data/dummy_val.jsonl"
  max_prompt_len: 512
  max_gen_len: 384
  loader_type: "jsonl"
  shuffle_data: true

rewards:
  - name: "code_execution"
    weight: 0.80
    config:
      timeout: 3 # seconds
  - name: "semantic_similarity"
    weight: 0.20
    config:
      method: "jaccard"

evaluation:
  - name: "human_eval"
    config:
      k_values: [1, 2]   # Calculate pass@1 and pass@2
      num_samples: 10    # Number of problems to evaluate

2025-10-07 21:51:13,258 INFO    MainThread:64113 [wandb_setup.py:_flush():81] Current SDK version is 0.21.3
2025-10-07 21:51:13,258 INFO    MainThread:64113 [wandb_setup.py:_flush():81] Configure stats pid to 64113
2025-10-07 21:51:13,258 INFO    MainThread:64113 [wandb_setup.py:_flush():81] Loading settings from /Users/adeelahmad/.config/wandb/settings
2025-10-07 21:51:13,258 INFO    MainThread:64113 [wandb_setup.py:_flush():81] Loading settings from /Users/adeelahmad/work/themlx/mlx_rl_trainer/mlx_rl_trainer/wandb/settings
2025-10-07 21:51:13,258 INFO    MainThread:64113 [wandb_setup.py:_flush():81] Loading settings from environment variables
2025-10-07 21:51:13,258 INFO    MainThread:64113 [wandb_init.py:setup_run_log_directory():686] Logging user logs to /Users/adeelahmad/work/themlx/mlx_rl_trainer/mlx_rl_trainer/wandb/run-20251007_215113-20251007_215112_078e5a91/logs/debug.log
2025-10-07 21:51:13,258 INFO    MainThread:64113 [wandb_init.py:setup_run_log_directory():687] Logging internal logs to /Users/adeelahmad/work/themlx/mlx_rl_trainer/mlx_rl_trainer/wandb/run-20251007_215113-20251007_215112_078e5a91/logs/debug-internal.log
2025-10-07 21:51:13,258 INFO    MainThread:64113 [wandb_init.py:init():813] calling init triggers
2025-10-07 21:51:13,258 INFO    MainThread:64113 [wandb_init.py:init():818] wandb.init called with sweep_config: {}
config: {'trainer': {'algorithm': 'grpo', 'output_dir': 'outputs/code_gen_run_001/20251007_215112_078e5a91', 'num_training_steps': 1000, 'learning_rate': 2e-06, 'ppo_batch_size': 1, 'num_rollout_samples': 3, 'grad_accum_steps': 1, 'grpo_beta': 0.05, 'seed': 42, 'optimizer_beta1': 0.9, 'optimizer_beta2': 0.95, 'optimizer_weight_decay': 0.01, 'grad_clip_norm': 0.5, 'lr_schedule_config': {'name': 'cosine_decay', 'arguments': [2e-06, 500, 2e-07], 'warmup': 500, 'warmup_init': 2e-07}, 'use_grad_checkpointing': False, 'grad_checkpoint_layers': 0, 'low_band': (0, 15), 'mid_band': (16, 23), 'top_band': (24, 35), 'low_mul': 0.1, 'mid_mul': 0.95, 'top_mul': 1.5, 'head_mul': 1.2, 'train_layer_start': 26, 'train_layer_end': 35, 'use_custom_batch_builder': False, 'invalid_sample_layers': '33,34,35', 'invalid_sample_frequency': 2, 'eval_every': 100, 'reward_smoothing_window': 20}, 'model': {'model_path': '/Users/adeelahmad/work/SiLLM-examples/helpsteer/mlx-grpo/outy1266_align_last30/latest', 'ref_model_path': '/Users/adeelahmad/work/SiLLM-examples/helpsteer/mlx-grpo/outy1266_align_last30/latest', 'use_lora': False, 'lora_rank': 16, 'lora_alpha': 16.0, 'lora_dropout': 0.0, 'lora_scale_by_rank': True, 'lora_target_modules': ['q_proj', 'k_proj', 'v_proj', 'o_proj', 'gate_proj', 'up_proj', 'down_proj']}, 'generation': {'think_start_tag': '<think>', 'think_end_tag': '</think>', 'answer_start_tag': '<answer>', 'answer_end_tag': '</answer>', 'think_boost_tokens': 32, 'think_temperature': 0.23, 'answer_temperature': 0.24, 'sampling_top_p': 0.7, 'sampling_min_p': 0.02, 'sampling_top_k': 20, 'repetition_penalty': 1.15, 'repetition_context_size': 20, 'min_think_tokens': 32, 'think_end_early_bias': -12.0, 'bias_answer_start_after_min_think': True, 'bias_close_think': 9.0, 'bias_answer_start': 6.0, 'punish_extra_think_end': -12.0, 'punish_reopen_think': -10.0, 'punish_reopen_answer': -9.0, 'bias_eos_after_answer': 3.0, 'hard_mask_mcq_first_token': True, 'mcq_letter_lift': 8.0, 'mcq_ban_first_bias': -14.0, 'nonmcq_ban_first_bias': -12.0, 'mcq_close_after_k': 1, 'min_answer_tokens': 8, 'min_answer_tokens_mcq': 1, 'mcq_answer_end_bias': 9.0, 'ban_phrases_for_bias': ['I think the answer', 'I believe that', 'Confused', 'stuck', 'frustrated'], 'encourage_phrases_for_bias': ['chk', 'calc', '∴', 'w/'], 'encourage_think_bias': 4.5, 'ban_think_bias': -3.0, 'allow_tool_calls': True, 'tool_call_penalty': 0.0, 'think_length_target_min': 32, 'think_length_target_max': 128, 'think_length_penalty_strength': 0.15}, 'rewards': [{'name': 'code_execution', 'weight': 0.8, 'config': {'timeout': 3}}, {'name': 'semantic_similarity', 'weight': 0.2, 'config': {'method': 'jaccard'}}], 'data': {'train_path': '/Users/adeelahmad/work/SiLLM-examples/helpsteer/mlx-grpo/judge/train.jsonl', 'val_path': '/Users/adeelahmad/work/SiLLM-examples/helpsteer/mlx-grpo/judge/valid.jsonl', 'max_prompt_len': 512, 'max_gen_len': 384, 'loader_type': 'jsonl', 'shuffle_data': True, 'dataset_prompt_key': 'prompt', 'dataset_answer_key': 'completion', 'dataset_filter_keywords': ['http://', '**other**', 'https://', 'png', 'jpg', 'Another way', 'Adeel']}, 'evaluation': [{'name': 'human_eval', 'config': {'k_values': [1, 2], 'num_samples': 10}}], 'checkpointing': {'save_dir': './checkpoints', 'save_every': 10, 'keep_last_n': 3, 'save_optimizer_state': False}, 'monitoring': {'use_wandb': True, 'wandb_project': 'mlx-grpo', 'wandb_entity': None, 'wandb_run_name': None, 'log_samples_every': 1, 'max_logged_samples': 50, 'log_prompts': True, 'sample_log_path': None}, 'max_kv_size': 1536, 'system_prompt': 'THINKING RULES - Use maximally compressed notation:\n\n    ═══ SYMBOLS & NOTATION ═══\n    Math: ∴(therefore) ∵(because) ⇒(implies) ≈(approx) ∈(in) ∀(forall) ∃(exists) ≠ ≤ ≥\n    Logic: ✓(yes) ✗(no) ?(unknown) !(important) ⚠(warning) ∧(and) ∨(or) ¬(not) ⊕(xor)\n    Flow: →(then) ←(from) ↔(bidirect) ⇄(exchange) ▸(next) ◂(prev) ⊃(implies) ⊂(subset)\n    Status: ✓(done) ○(pending) ●(active) ◐(partial) ⊗(blocked) ⊘(invalid)\n\n    ═══ UNIVERSAL ABBREVIATIONS ═══\n    w/(with) w/o(without) b/c(because) re:(regarding) vs(versus) via per thru\n    @(at/location) #(number) &(and) +(plus/also) -(minus/without) /(per/or) |(or/pipe)\n    i.e.(that is) e.g.(example) etc.(and so on) cf(compare) viz(namely) NB(note well)\n\n    ═══ ACTION SHORTHAND ═══\n    chk(check) calc(calculate) eval(evaluate) cmp(compare) est(estimate) approx(approximate)\n    find get set test run init proc(process) upd(update) del(delete) add sub mul div\n    verify confirm validate analyze extract parse transform merge split filter sort\n\n    ═══ DOMAIN-SPECIFIC SHORTHAND ═══\n    - CODE/TECH: func var obj arr str int bool dict list async await req res API DB\n      impl(implement) refactor debug deploy config exec cmd arg param ret val idx len\n\n    - BUSINESS: rev(revenue) exp(expense) proj(projection) KPI ROI Q1/Q2/Q3/Q4 YoY MoM\n      stakeholder cust(customer) mkt(market) comp(competitor) strat(strategy) ops(operations)\n\n    - SCIENCE: exp(experiment) obs(observation) hyp(hypothesis) ctrl(control) var(variable)\n      sig(significant) corr(correlation) data pt(point) meas(measure) temp pres vol mass\n\n    - LOGIC/REASONING: IF/THEN/ELSE WHEN/WHILE FOR/EACH CASE/SWITCH TRY/CATCH\n      premise→conclusion assumption→inference cause→effect condition→result\n\n    ═══ TIME & QUANTITY ═══\n    mins hrs days wks mos yrs NOW ASAP prev next cur(current) hist(historical)\n    approx ~100 <10 >50 ≤5 ≥20 between±5 range[1-10] max min avg sum total count\n\n    ═══ COMPARISON & RELATIONSHIPS ═══\n    better/worse higher/lower more/less same≠diff equal>unequal similar≈different\n    vs opt1/opt2/opt3 pros/cons trade-off cost/benefit risk/reward\n\n    ═══ STRICTLY FORBIDDEN PHRASES ═══\n    ✗ "I think" "I believe" "I feel" "In my opinion" "It seems" "It appears"\n    ✗ "Let me" "I should" "I need to" "I want to" "I\'m going to"\n    ✗ "This is interesting" "Looking at" "Considering" "Taking into account"\n    ✗ "First of all" "On the other hand" "In this case" "As we can see"\n    ✗ "It\'s worth noting" "It\'s important to" "We should consider"\n    ✗ "Taking into account" "With that in mind" "Given this information" "Based on this"\n    ✗ "Confused" "stuck" "frustrated" "Uncertain" "Unclear" "I\'m guessing"\n    ✗ "maybe the answer is" "I\'m not sure" "Probably" "Perhaps" "Possibly"\n    ✗ "Circular reasoning" "In some way" "Magically" "For some reason" "Too complicated" "It just works"\n    ✗ "Something is off" "Wait, but" "Wait, maybe" "Wait, actually" "Hold on" "another thought:"\n    ✗ "Alternatively", "Actually", "Or maybe", "Flowery language, hedging, or conversational filler"\n    ✗ "Furthermore", "Moreover", "Nevertheless", "Nonetheless", "Subsequently", "Therefore, it can be concluded", "In conclusion", "To summarize", "As mentioned previously"\n    ✗ Any emoji unless user explicitly requests them\n\n    ═══ REQUIRED FORMAT ═══\n    - Write as compact telegraphic notes, NOT full sentences\n    - Use vertical lists w/ bullets or dashes for multi-items\n    - Group related info with indentation or symbols\n    - One idea per line when possible\n    - Omit articles (a/an/the), auxiliary verbs (is/are/was), obvious subjects\n\n    EXAMPLES:\n    ❌ BAD: "I think we should first check if the value is greater than 10, and if it is, then we need to calculate..."\n    ✓ GOOD: "chk val>10 → calc x²+3 → ∴ result≈42"\n\n    ❌ BAD: "Looking at the data, it seems that the customer retention rate is lower than expected"\n    ✓ GOOD: "data: cust retention<expected (est 65% vs target 80%) → need improve"\n\n    ❌ BAD: "Let me break this down. We have three options here. Option A would cost more but..."\n    ✓ GOOD: "3 opts: A(↑cost ✓quality) B(balanced) C(↓cost ✗quality) → rec: B"\n\n    ═══ WHEN UNCERTAIN ═══ DO NOT guess or assume. Instead: ? = flag uncertainty w/ question mark ASK: "need clarification on X" or "X not specified - options: A/B/C?" CONSTRAINT: "cannot solve b/c: missing info Y" If problem unsolvable → state why concisely, don\'t elaborate Think like: debugger output, medical chart notes, trading floor shorthand, or military briefing. COMPRESS EVERYTHING. Every word must earn its place.', 'use_paged_kv_cache': True, 'kv_cache_block_size': 16, 'kv_cache_num_blocks': 2048, 'allow_cross_arch_ref': False, 'align_bridge_path': None, 'align_bridge_weight': 1.0, 'align_pool': 'mean', 'align_after_tag': '</think>', 'run_id': '20251007_215112_078e5a91', '_wandb': {}}
2025-10-07 21:51:13,258 INFO    MainThread:64113 [wandb_init.py:init():854] starting backend
2025-10-07 21:51:13,482 INFO    MainThread:64113 [wandb_init.py:init():857] sending inform_init request
2025-10-07 21:51:13,507 INFO    MainThread:64113 [wandb_init.py:init():865] backend started and connected
2025-10-07 21:51:13,511 INFO    MainThread:64113 [wandb_init.py:init():936] updated telemetry
2025-10-07 21:51:13,532 INFO    MainThread:64113 [wandb_init.py:init():960] communicating run to backend with 90.0 second timeout
2025-10-07 21:51:14,725 INFO    MainThread:64113 [wandb_init.py:init():1011] starting run threads in backend
2025-10-07 21:51:15,173 INFO    MainThread:64113 [wandb_run.py:_console_start():2494] atexit reg
2025-10-07 21:51:15,174 INFO    MainThread:64113 [wandb_run.py:_redirect():2342] redirect: wrap_raw
2025-10-07 21:51:15,174 INFO    MainThread:64113 [wandb_run.py:_redirect():2411] Wrapping output streams.
2025-10-07 21:51:15,174 INFO    MainThread:64113 [wandb_run.py:_redirect():2434] Redirects installed.
2025-10-07 21:51:15,175 INFO    MainThread:64113 [wandb_init.py:init():1057] run started, returning control to user process
2025-10-07 21:54:29,257 INFO    MainThread:64113 [wandb_run.py:_finish():2260] finishing run adeelahmad99/mlx-grpo/20251007_215112_078e5a91
2025-10-07 21:54:29,257 INFO    MainThread:64113 [wandb_run.py:_atexit_cleanup():2459] got exitcode: 0
2025-10-07 21:54:29,258 INFO    MainThread:64113 [wandb_run.py:_restore():2441] restore
2025-10-07 21:54:29,258 INFO    MainThread:64113 [wandb_run.py:_restore():2447] restore done
2025-10-07 21:54:33,448 INFO    MainThread:64113 [wandb_run.py:_footer_sync_info():3855] logging synced files
